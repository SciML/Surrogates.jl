<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimization · Surrogates.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://surrogates.sciml.ai/stable/optimizations/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Surrogates.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Surrogates.jl: Surrogate models and optimization for scientific machine learning</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/">Basics</a></li><li><a class="tocitem" href="../radials/">Radials</a></li><li><a class="tocitem" href="../kriging/">Kriging</a></li><li><a class="tocitem" href="../abstractgps/">Gaussian Process</a></li><li><a class="tocitem" href="../lobachevsky/">Lobachevsky</a></li><li><a class="tocitem" href="../LinearSurrogate/">Linear</a></li><li><a class="tocitem" href="../InverseDistance/">InverseDistance</a></li><li><a class="tocitem" href="../randomforest/">RandomForest</a></li><li><a class="tocitem" href="../secondorderpoly/">SecondOrderPolynomial</a></li><li><a class="tocitem" href="../neural/">NeuralSurrogate</a></li><li><a class="tocitem" href="../wendland/">Wendland</a></li><li><a class="tocitem" href="../polychaos/">Polynomial Chaos</a></li><li><a class="tocitem" href="../variablefidelity/">Variable Fidelity</a></li><li><a class="tocitem" href="../gek/">Gradient Enhanced Kriging</a></li><li><a class="tocitem" href="../gekpls/">GEKPLS</a></li></ul></li><li><span class="tocitem">User guide</span><ul><li><a class="tocitem" href="../samples/">Samples</a></li><li><a class="tocitem" href="../surrogate/">Surrogates</a></li><li class="is-active"><a class="tocitem" href>Optimization</a><ul class="internal"><li><a class="tocitem" href="#Adding-another-optimization-method"><span>Adding another optimization method</span></a></li></ul></li></ul></li><li><span class="tocitem">Benchmarks</span><ul><li><a class="tocitem" href="../sphere_function/">Sphere function</a></li><li><a class="tocitem" href="../lp/">Lp norm</a></li><li><a class="tocitem" href="../rosenbrock/">Rosenbrock</a></li><li><a class="tocitem" href="../tensor_prod/">Tensor product</a></li><li><a class="tocitem" href="../cantilever/">Cantilever beam</a></li><li><a class="tocitem" href="../water_flow/">Water Flow function</a></li><li><a class="tocitem" href="../welded_beam/">Welded beam function</a></li><li><a class="tocitem" href="../BraninFunction/">Branin function</a></li><li><a class="tocitem" href="../ackley/">Ackley function</a></li><li><a class="tocitem" href="../gramacylee/">Gramacy &amp; Lee Function</a></li><li><a class="tocitem" href="../Salustowicz/">Salustowicz Benchmark</a></li><li><a class="tocitem" href="../multi_objective_opt/">Multi objective optimization</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User guide</a></li><li class="is-active"><a href>Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/Surrogates.jl/blob/master/docs/src/optimizations.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimization-techniques"><a class="docs-heading-anchor" href="#Optimization-techniques">Optimization techniques</a><a id="Optimization-techniques-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-techniques" title="Permalink"></a></h1><ul><li>SRBF</li></ul><article class="docstring"><header><a class="docstring-binding" id="Surrogates.surrogate_optimize-Tuple{Function, SRBF, Any, Any, AbstractSurrogate, SamplingAlgorithm}" href="#Surrogates.surrogate_optimize-Tuple{Function, SRBF, Any, Any, AbstractSurrogate, SamplingAlgorithm}"><code>Surrogates.surrogate_optimize</code></a> — <span class="docstring-category">Method</span></header><section><div><p>The main idea is to pick the new evaluations from a set of candidate points where each candidate point is generated as an N(0, sigma^2) distributed perturbation from the current best solution. The value of sigma is modified based on progress and follows the same logic as in many trust region methods: we increase sigma if we make a lot of progress (the surrogate is accurate) and decrease sigma when we aren’t able to make progress (the surrogate model is inaccurate). More details about how sigma is updated is given in the original papers.</p><p>After generating the candidate points, we predict their objective function value and compute the minimum distance to the previously evaluated point. Let the candidate points be denoted by C and let the function value predictions be s(x_i) and the distance values be d(x_i), both rescaled through a linear transformation to the interval [0,1]. This is done to put the values on the same scale. The next point selected for evaluation is the candidate point x that minimizes the weighted-distance merit function:</p><p><span>$merit(x) = ws(x) + (1-w)(1-d(x))$</span></p><p>where <span>$0 \leq w \leq 1$</span>. That is, we want a small function value prediction and a large minimum distance from the previously evaluated points. The weight w is commonly cycled between a few values to achieve both exploitation and exploration. When w is close to zero, we do pure exploration, while w close to 1 corresponds to exploitation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Surrogates.jl/blob/4dc62e76ecc6be1de772406ee889c6a8f705d05b/src/Optimization.jl#L51-L77">source</a></section></article><ul><li>LCBS</li></ul><article class="docstring"><header><a class="docstring-binding" id="Surrogates.surrogate_optimize-Tuple{Function, LCBS, Any, Any, Any, SamplingAlgorithm}" href="#Surrogates.surrogate_optimize-Tuple{Function, LCBS, Any, Any, Any, SamplingAlgorithm}"><code>Surrogates.surrogate_optimize</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This is an implementation of Lower Confidence Bound (LCB), a popular acquisition function in Bayesian optimization. Under a Gaussian process (GP) prior, the goal is to minimize:</p><p><span>$LCB(x) := E[x] - k * \sqrt{(V[x])}$</span></p><p>default value <span>$k = 2$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Surrogates.jl/blob/4dc62e76ecc6be1de772406ee889c6a8f705d05b/src/Optimization.jl#L437-L445">source</a></section></article><ul><li>EI</li></ul><article class="docstring"><header><a class="docstring-binding" id="Surrogates.surrogate_optimize-Tuple{Function, EI, Any, Any, Any, SamplingAlgorithm}" href="#Surrogates.surrogate_optimize-Tuple{Function, EI, Any, Any, Any, SamplingAlgorithm}"><code>Surrogates.surrogate_optimize</code></a> — <span class="docstring-category">Method</span></header><section><div><p>This is an implementation of Expected Improvement (EI), arguably the most popular acquisition function in Bayesian optimization. Under a Gaussian process (GP) prior, the goal is to maximize expected improvement:</p><p><span>$EI(x) := E[max(f_{best}-f(x),0)$</span></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Surrogates.jl/blob/4dc62e76ecc6be1de772406ee889c6a8f705d05b/src/Optimization.jl#L572-L581">source</a></section></article><ul><li>DYCORS</li></ul><article class="docstring"><header><a class="docstring-binding" id="Surrogates.surrogate_optimize-Tuple{Function, DYCORS, Any, Any, AbstractSurrogate, SamplingAlgorithm}" href="#Surrogates.surrogate_optimize-Tuple{Function, DYCORS, Any, Any, AbstractSurrogate, SamplingAlgorithm}"><code>Surrogates.surrogate_optimize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">  surrogate_optimize(obj::Function,::DYCORS,lb::Number,ub::Number,surr1::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)</code></pre><p>This is an implementation of the DYCORS strategy by Regis and Shoemaker: Rommel G Regis and Christine A Shoemaker. Combining radial basis function surrogates and dynamic coordinate search in high-dimensional expensive black-box optimization. Engineering Optimization, 45(5): 529–555, 2013. This is an extension of the SRBF strategy that changes how the candidate points are generated. The main idea is that many objective functions depend only on a few directions so it may be advantageous to perturb only a few directions. In particular, we use a perturbation probability to perturb a given coordinate and decrease this probability after each function evaluation so fewer coordinates are perturbed later in the optimization.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Surrogates.jl/blob/4dc62e76ecc6be1de772406ee889c6a8f705d05b/src/Optimization.jl#L838-L852">source</a></section></article><ul><li>SOP</li></ul><article class="docstring"><header><a class="docstring-binding" id="Surrogates.surrogate_optimize-Tuple{Function, SOP, Number, Number, AbstractSurrogate, SamplingAlgorithm}" href="#Surrogates.surrogate_optimize-Tuple{Function, SOP, Number, Number, AbstractSurrogate, SamplingAlgorithm}"><code>Surrogates.surrogate_optimize</code></a> — <span class="docstring-category">Method</span></header><section><div><p>surrogate<em>optimize(obj::Function,::SOP,lb::Number,ub::Number,surr::AbstractSurrogate,sample</em>type::SamplingAlgorithm;maxiters=100,num<em>new</em>samples=100)</p><p>SOP Surrogate optimization method, following closely the following papers:</p><pre><code class="nohighlight hljs">- SOP: parallel surrogate global optimization with Pareto center selection for computationally expensive single objective problems by Tipaluck Krityakierne
- Multiobjective Optimization Using Evolutionary Algorithms by Kalyan Deb</code></pre><p>#Suggested number of new_samples = min(500*d,5000)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Surrogates.jl/blob/4dc62e76ecc6be1de772406ee889c6a8f705d05b/src/Optimization.jl#L1031-L1039">source</a></section></article><h2 id="Adding-another-optimization-method"><a class="docs-heading-anchor" href="#Adding-another-optimization-method">Adding another optimization method</a><a id="Adding-another-optimization-method-1"></a><a class="docs-heading-anchor-permalink" href="#Adding-another-optimization-method" title="Permalink"></a></h2><p>To add another optimization method, you just need to define a new SurrogateOptimizationAlgorithm and write its corresponding algorithm, overloading the following:</p><pre><code class="nohighlight hljs">surrogate_optimize(obj::Function,::NewOptimizatonType,lb,ub,surr::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../surrogate/">« Surrogates</a><a class="docs-footer-nextpage" href="../sphere_function/">Sphere function »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Friday 9 September 2022 14:57">Friday 9 September 2022</span>. Using Julia version 1.8.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
