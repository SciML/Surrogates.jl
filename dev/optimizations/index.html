<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimization · Surrogates.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Surrogates.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Overview</a></li><li><span class="toctext">User guide</span><ul><li><a class="toctext" href="../samples/">Samples</a></li><li><a class="toctext" href="../surrogate/">Surrogates</a></li><li class="current"><a class="toctext" href>Optimization</a><ul class="internal"><li><a class="toctext" href="#Adding-another-optimization-method-1">Adding another optimization method</a></li></ul></li></ul></li><li><a class="toctext" href="../tutorials/">Tutorials</a></li><li><a class="toctext" href="../contributing/">Contributing</a></li></ul></nav><article id="docs"><header><nav><ul><li>User guide</li><li><a href>Optimization</a></li></ul><a class="edit-page" href="https://github.com/JuliaDiffEq/Surrogates.jl/blob/master/docs/src/optimizations.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Optimization</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Optimization-techniques-1" href="#Optimization-techniques-1">Optimization techniques</a></h1><ul><li>SRBF</li></ul><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Surrogates.surrogate_optimize-Tuple{Function,SRBF,Any,Any,AbstractSurrogate,SamplingAlgorithm}" href="#Surrogates.surrogate_optimize-Tuple{Function,SRBF,Any,Any,AbstractSurrogate,SamplingAlgorithm}"><code>Surrogates.surrogate_optimize</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>The main idea is to pick the new evaluations from a set of candidate points where each candidate point is generated as an N(0, sigma^2) distributed perturbation from the current best solution. The value of sigma is modified based on progress and follows the same logic as in many trust region methods; we increase sigma if we make a lot of progress (the surrogate is accurate) and decrease sigma when we aren’t able to make progress (the surrogate model is inaccurate). More details about how sigma is updated is given in the original papers.</p><p>After generating the candidate points we predict their objective function value and compute the minimum distance to previously evaluated point. Let the candidate points be denoted by C and let the function value predictions be s(x_i) and the distance values be d(x_i), both rescaled through a linear transformation to the interval [0,1]. This is done to put the values on the same scale. The next point selected for evaluation is the candidate point x that minimizes the weighted-distance merit function:</p><p><span>$merit(x) = ws(x) + (1-w)(1-d(x))$</span></p><p>where <span>$0 \leq w \leq 1$</span>. That is, we want a small function value prediction and a large minimum distance from previously evalauted points. The weight w is commonly cycled between a few values to achieve both exploitation and exploration. When w is close to zero we do pure exploration while w close to 1 corresponds to explotation.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaDiffEq/Surrogates.jl/blob/1ad1181253449a4ce9ec35c0e49c5dc1c536d20a/src/Optimization.jl#L39-L65">source</a></section><ul><li>LCBS</li></ul><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Surrogates.surrogate_optimize-Tuple{Function,LCBS,Any,Any,Kriging,SamplingAlgorithm}" href="#Surrogates.surrogate_optimize-Tuple{Function,LCBS,Any,Any,Kriging,SamplingAlgorithm}"><code>Surrogates.surrogate_optimize</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>This is an implementation of Lower Confidence Bound (LCB), a popular acquisition function in Bayesian optimization. Under a Gaussian process (GP) prior, the goal is to minimize:</p><p><span>$LCB(x) := E[x] - k * \sqrt{(V[x])}$</span></p><p>default value <span>$k = 2$</span>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaDiffEq/Surrogates.jl/blob/1ad1181253449a4ce9ec35c0e49c5dc1c536d20a/src/Optimization.jl#L401-L409">source</a></section><ul><li>EI</li></ul><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Surrogates.surrogate_optimize-Tuple{Function,EI,Any,Any,Kriging,SamplingAlgorithm}" href="#Surrogates.surrogate_optimize-Tuple{Function,EI,Any,Any,Kriging,SamplingAlgorithm}"><code>Surrogates.surrogate_optimize</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>This is an implementation of Expected Improvement (EI), arguably the most popular acquisition function in Bayesian optimization. Under a Gaussian process (GP) prior, the goal is to maximize expected improvement:</p><p><span>$EI(x) := E[max(f_{best}-f(x),0)$</span></p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaDiffEq/Surrogates.jl/blob/1ad1181253449a4ce9ec35c0e49c5dc1c536d20a/src/Optimization.jl#L512-L521">source</a></section><ul><li>DYCORS</li></ul><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Surrogates.surrogate_optimize-Tuple{Function,DYCORS,Any,Any,Kriging,SamplingAlgorithm}" href="#Surrogates.surrogate_optimize-Tuple{Function,DYCORS,Any,Any,Kriging,SamplingAlgorithm}"><code>Surrogates.surrogate_optimize</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>This is an implementation of the DYCORS strategy by Regis and Shoemaker:</p><p>Rommel G Regis and Christine A Shoemaker. Combining radial basis function surrogates and dynamic coordinate search in high-dimensional expensive black-box optimization. Engineering Optimization, 45(5): 529–555, 2013.</p><p>This is an extension of the SRBF strategy that changes how the candidate points are generated. The main idea is that many objective functions depend only on a few directions so it may be advantageous to perturb only a few directions. In particular, we use a perturbation probability to perturb a given coordinate and decrease this probability after each function evaluation so fewer coordinates are perturbed later in the optimization.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaDiffEq/Surrogates.jl/blob/1ad1181253449a4ce9ec35c0e49c5dc1c536d20a/src/Optimization.jl#L750-L763">source</a></section><h2><a class="nav-anchor" id="Adding-another-optimization-method-1" href="#Adding-another-optimization-method-1">Adding another optimization method</a></h2><p>To add another optimization method, you just need to define a new SurrogateOptimizationAlgorithm and write its corresponding algorithm, overloading the following:</p><pre><code class="language-none">surrogate_optimize(obj::Function,::NewOptimizatonType,lb,ub,surr::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)</code></pre><footer><hr/><a class="previous" href="../surrogate/"><span class="direction">Previous</span><span class="title">Surrogates</span></a><a class="next" href="../tutorials/"><span class="direction">Next</span><span class="title">Tutorials</span></a></footer></article></body></html>
